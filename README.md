# üõçÔ∏è dbt-Databricks Analytics - Retail Data Warehouse

[![dbt](https://img.shields.io/badge/dbt-1.7+-orange.svg)](https://docs.getdbt.com)
[![Databricks](https://img.shields.io/badge/Databricks-Compatible-red.svg)](https://databricks.com)

A comprehensive dbt demo project that implements a modern data warehouse for a retail company, following data modeling best practices and medallion architecture patterns.

## üìã Table of Contents

- [üéØ Project Overview](#-project-overview)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üìä Data Model](#-data-model)
- [üöÄ Setup & Installation](#-setup--installation)
- [üìà dbt Lineage](#-dbt-lineage)
- [üõ†Ô∏è dbt Commands](#Ô∏è-dbt-commands)
- [üìñ Documentation](#-documentation)

## üéØ Project Overview

This project demonstrates the implementation of a complete data warehouse for a retail company using dbt (data build tool). The project includes:

- **Medallion Architecture**: Bronze (Raw) ‚Üí Silver (Staging) ‚Üí Gold (Marts)
- **Dimensional Modeling**: Facts and dimensions for OLAP analysis
- **Data Quality Tests**: Automated data validations
- **Documentation**: Auto-generated and maintained
- **Business Analytics**: BI-ready insights

### üé™ Use Cases Covered

- üìä **Sales Analytics**: Performance metrics by store, product, and employee
- üë• **Customer Segmentation**: Automated classification based on behavior
- üí∞ **Profitability Analysis**: Margin and profitability analysis by dimensions
- üéØ **Target Achievement**: Comparison against defined targets
- üìà **Temporal Trends**: Seasonal and temporal pattern analysis

## üèóÔ∏è Architecture

### Medallion Architecture Overview

```mermaid
graph TD
    subgraph Sources ["üì• Data Sources"]
        S1[Raw CSV Files]
        S2[Database Extracts] 
        S3[API Data]
    end
    
    subgraph Bronze ["ü•â Bronze Layer - Raw Data"]
        B1[(customers)]
        B2[(orders)]
        B3[(order_items)]
        B4[(products)]
        B5[(employees)]
        B6[(stores)]
        B7[(suppliers)]
        B8[(dates)]
    end
    
    subgraph Silver ["ü•à Silver Layer - Cleaned Data"]
        C1[stg_customers]
        C2[stg_orders]
        C3[stg_order_items]
        C4[stg_products]
        C5[stg_employees]
        C6[stg_stores]
        C7[stg_suppliers]
        C8[stg_dates]
    end
    
    subgraph Gold ["ü•á Gold Layer - Business Ready"]
        direction TB
        subgraph Dimensions ["üìä Dimensions"]
            D1[dim_customers]
            D2[dim_products] 
            D3[dim_employees]
            D4[dim_stores]
            D5[dim_suppliers]
            D6[dim_dates]
        end
        subgraph Facts ["üìà Facts"]
            F1[fct_orders]
            F2[fct_customer_segmentation]
            F3[fct_store_performance]
        end
    end
    
    Sources --> Bronze
    Bronze --> Silver
    Silver --> Gold
    
    classDef bronze fill:#cd853f,stroke:#8b4513,stroke-width:2px,color:#fff
    classDef silver fill:#c0c0c0,stroke:#696969,stroke-width:2px,color:#000
    classDef gold fill:#ffd700,stroke:#daa520,stroke-width:2px,color:#000
    classDef source fill:#98fb98,stroke:#228b22,stroke-width:2px,color:#000
    
    class B1,B2,B3,B4,B5,B6,B7,B8 bronze
    class C1,C2,C3,C4,C5,C6,C7,C8 silver
    class D1,D2,D3,D4,D5,D6,F1,F2,F3 gold
    class S1,S2,S3 source
```

## üìä Data Model

### Star Schema Design

Our data model follows a classic retail star schema pattern with comprehensive dimensions and facts:

```mermaid
erDiagram
    dim_dates {
        date date_id PK
        varchar month
        varchar day_of_week
        varchar season
        varchar shopping_season
        varchar quarter_name
        boolean is_weekend
    }
    
    dim_customers {
        int customer_id PK
        varchar customer_name
        varchar email
        varchar value_segment
        varchar activity_status
        varchar region
        decimal lifetime_revenue
        int total_orders
    }
    
    dim_products {
        int product_id PK
        varchar product_name
        varchar category
        varchar category_group
        varchar price_tier
        varchar product_status
        decimal retail_price
        decimal margin_percent
    }
    
    dim_employees {
        int employee_id PK
        varchar employee_name
        varchar department
        varchar tenure_category
        varchar performance_tier
        varchar job_title
        int manager_id
    }
    
    dim_stores {
        int store_id PK
        varchar store_name
        varchar store_type
        varchar region
        varchar operating_status
        decimal monthly_target
        varchar performance_status
    }
    
    dim_suppliers {
        int supplier_id PK
        varchar supplier_name
        varchar supplier_tier
        varchar region
        int total_products
        varchar portfolio_diversity
    }
    
    fct_orders {
        int order_id PK
        date order_date FK
        int customer_id FK
        int employee_id FK
        int store_id FK
        varchar status_desc
        decimal revenue
        int item_count
        int total_quantity
    }

    %% Relationships
    dim_dates ||--o{ fct_orders : order_date
    dim_customers ||--o{ fct_orders : customer_id
    dim_employees ||--o{ fct_orders : employee_id
    dim_stores ||--o{ fct_orders : store_id
    dim_suppliers ||--o{ dim_products : supplier_id
    dim_products ||--o{ fct_orders : "via order_items"
    dim_employees ||--o{ dim_employees : "reports_to"
```

### ü•á Gold Layer (Marts)

#### Main Dimensions

| Dimension | Description | Key Attributes |
|-----------|-------------|-----------------|
| `dim_customers` | Customers with segmentation and metrics | segment, region, status, LTV |
| `dim_products` | Products with categories and performance | category, price tier, status |
| `dim_employees` | Employees with roles and performance | department, level, tenure |
| `dim_stores` | Stores with targets and classification | region, type, performance vs target |
| `dim_suppliers` | Suppliers with portfolio metrics | tier, diversity, performance |
| `dim_dates` | Complete calendar with attributes | season, holidays, fiscal periods |

#### Fact Tables

| Fact | Description | Key Metrics |
|-------|-------------|---------------------|
| `fct_orders` | Sales transactions | revenue, quantity, items |
| `fct_customer_segmentation` | Customer segmentation | segment, activity, classification |
| `fct_store_performance` | Store performance | revenue vs target, orders, customers |

## üìà dbt Lineage

### Complete Data Flow

The following diagram shows the complete dbt lineage from bronze tables through to final marts:

> **Note**: After running `dbt docs generate && dbt docs serve`, you can explore the interactive lineage graph at `http://localhost:8080`

```mermaid
flowchart LR
    %% Bronze Layer
    subgraph Bronze ["ü•â Bronze Tables"]
        direction TB
        customers[(customers)]
        orders[(orders)]
        order_items[(order_items)]
        products[(products)]
        employees[(employees)]
        stores[(stores)]
        suppliers[(suppliers)]
        dates[(dates)]
    end
    
    %% Seeds
    subgraph Seeds ["üå± Reference Data"]
        direction TB
        cs[customer_segments]
        er[employee_roles] 
        pc[product_categories]
        st[store_targets]
        osm[order_status_mapping]
    end
    
    %% Silver Layer
    subgraph Silver ["ü•à Staging Models"]
        direction TB
        stg_customers[stg_customers]
        stg_orders[stg_orders]
        stg_order_items[stg_order_items]
        stg_products[stg_products]
        stg_employees[stg_employees]
        stg_stores[stg_stores]
        stg_suppliers[stg_suppliers]
        stg_dates[stg_dates]
    end
    
    %% Gold Layer - Dimensions
    subgraph Dimensions ["üìä Dimensions"]
        direction TB
        dim_customers[dim_customers]
        dim_products[dim_products]
        dim_employees[dim_employees]
        dim_stores[dim_stores]
        dim_suppliers[dim_suppliers]
        dim_dates[dim_dates]
    end
    
    %% Gold Layer - Facts
    subgraph Facts ["üìà Fact Tables"]
        direction TB
        fct_orders[fct_orders]
        fct_segmentation[fct_customer_segmentation]
        fct_performance[fct_store_performance]
        fct_profit[fct_store_monthly_profit]
    end
    
    %% Connections Bronze to Silver
    customers --> stg_customers
    orders --> stg_orders
    order_items --> stg_order_items
    products --> stg_products
    employees --> stg_employees
    stores --> stg_stores
    suppliers --> stg_suppliers
    dates --> stg_dates
    
    %% Connections Silver to Gold Dimensions
    stg_customers --> dim_customers
    stg_products --> dim_products
    stg_employees --> dim_employees
    stg_stores --> dim_stores
    stg_suppliers --> dim_suppliers
    stg_dates --> dim_dates
    
    %% Seeds to Dimensions
    cs --> dim_customers
    er --> dim_employees
    pc --> dim_products
    st --> dim_stores
    osm --> stg_orders
    
    %% Silver to Facts
    stg_orders --> fct_orders
    stg_order_items --> fct_orders
    
    %% Dimensions to Facts
    dim_customers --> fct_segmentation
    dim_stores --> fct_performance
    dim_stores --> fct_profit
    fct_orders --> fct_segmentation
    fct_orders --> fct_performance
    fct_orders --> fct_profit
    
    %% Styling
    classDef bronze fill:#8B4513,stroke:#654321,stroke-width:2px,color:#fff
    classDef silver fill:#A9A9A9,stroke:#696969,stroke-width:2px,color:#000
    classDef gold fill:#FFD700,stroke:#B8860B,stroke-width:2px,color:#000
    classDef seed fill:#90EE90,stroke:#32CD32,stroke-width:2px,color:#000
    
    class customers,orders,order_items,products,employees,stores,suppliers,dates bronze
    class stg_customers,stg_orders,stg_order_items,stg_products,stg_employees,stg_stores,stg_suppliers,stg_dates silver
    class dim_customers,dim_products,dim_employees,dim_stores,dim_suppliers,dim_dates,fct_orders,fct_segmentation,fct_performance,fct_profit gold
    class cs,er,pc,st,osm seed
```

## üöÄ Setup & Installation

### Prerequisites

- Python 3.8+
- Databricks workspace
- Git

### 1. Repository Clone

```bash
git clone https://github.com/your-user/dbt-databricks-analytics.git
cd dbt-databricks-analytics
```

### 2. Virtual Environment Setup

```bash
python -m venv dbt-env
source dbt-env/bin/activate  # On Windows: dbt-env\Scripts\activate
pip install -r requirements.txt
```

### 3. Databricks Configuration

Create your `profiles.yml` file in `~/.dbt/`:

```yaml
dbt_demo:
  target: dev
  outputs:
    dev:
      type: databricks
      catalog: dbt_demo
      schema: dev_{{ env_var('USER') }}
      host: "{{ env_var('DATABRICKS_HOST') }}"
      http_path: "{{ env_var('DATABRICKS_HTTP_PATH') }}"
      token: "{{ env_var('DATABRICKS_TOKEN') }}"
      threads: 4
    
    prod:
      type: databricks
      catalog: dbt_demo
      schema: prod
      host: "{{ env_var('DATABRICKS_HOST') }}"
      http_path: "{{ env_var('DATABRICKS_HTTP_PATH') }}"
      token: "{{ env_var('DATABRICKS_TOKEN') }}"
      threads: 8
```

### 4. Environment Variables

```bash
export DATABRICKS_HOST="your-workspace-url"
export DATABRICKS_HTTP_PATH="/sql/1.0/warehouses/your-warehouse-id"
export DATABRICKS_TOKEN="your-access-token"
export USER=$(whoami)
```

### 5. Initial Setup

```bash
# 1. Run setup scripts in Databricks SQL Editor
# - Execute setup/catalog_setup.sql
# - Execute setup/seed_data.sql

# 2. Load seeds and run models
dbt seed
dbt run
dbt test

# 3. Generate documentation
dbt docs generate
dbt docs serve --port 8080
```

## üõ†Ô∏è dbt Commands

### Essential Commands

```bash
# Verify connection
dbt debug

# Install dependencies
dbt deps

# Load seeds (reference data)
dbt seed

# Run all models
dbt run

# Run tests
dbt test

# Generate documentation
dbt docs generate
dbt docs serve --port 8080
```

### Selective Commands

```bash
# Only staging
dbt run --select staging

# One model and its dependencies
dbt run --select +fct_orders

# Modified models
dbt run --select state:modified

# Full refresh (recreate tables)
dbt run --full-refresh
```

### Development Commands

```bash
# Incremental mode for development
dbt run --select marts.core --vars '{is_test: true}'

# Clean
dbt clean

# Compile without running
dbt compile
```

## üìñ Documentation

### Interactive Documentation

Access the full interactive documentation:

```bash
dbt docs generate
dbt docs serve --port 8080
```

Features include:
- **Entity Relationship Diagrams**: Visual representation of table relationships
- **Lineage Graphs**: Complete data flow visualization
- **Column Documentation**: Detailed descriptions and data types
- **Test Results**: Data quality validation status
- **Source Freshness**: Data freshness monitoring

### Databricks Integration

To visualize lineage in Databricks:

1. Go to **Data** ‚Üí **Catalogs** ‚Üí `dbt_demo`
2. Explore generated tables in `silver` and `gold` schemas
3. Use **Lineage** tab for dependency visualization
4. Leverage **Query Profile** for performance analysis

<<<<<<< HEAD
---
*Built with ‚ù§Ô∏è using dbt and Databricks*
=======
### Project Structure

```
dbt-databricks-analytics/
‚îú‚îÄ‚îÄ üìÅ models/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ staging/              # ü•à Silver Layer - Clean data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_customers.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_orders.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_products.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ marts/               # ü•á Gold Layer - Business-ready
‚îÇ       ‚îú‚îÄ‚îÄ üìÅ core/            # Main dimensions and facts
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_customers.sql
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_products.sql
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fct_orders.sql
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ üìÅ finance/         # Financial metrics
‚îÇ           ‚îú‚îÄ‚îÄ fct_customer_segmentation.sql
‚îÇ           ‚îú‚îÄ‚îÄ fct_store_performance.sql
‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ üìÅ seeds/                   # Reference data
‚îú‚îÄ‚îÄ üìÅ tests/                   # Data quality tests
‚îú‚îÄ‚îÄ üìÅ analyses/               # Ad-hoc analyses
‚îú‚îÄ‚îÄ üìÅ macros/                 # Reusable code
‚îî‚îÄ‚îÄ üìÅ setup/                  # Initial setup scripts
```

## üîç Tests & Data Quality

### Automated Tests

The project includes comprehensive tests to ensure data quality:

- **Schema Tests**: `unique`, `not_null`, `accepted_values`, `relationships`
- **Singular Tests**: Business logic specific validations
- **dbt_utils Tests**: `at_least_one` for important metrics

### Running Tests

```bash
# All tests
dbt test

# Specific tests
dbt test --select staging
dbt test --select marts.core

# Tests with data storage
dbt test --store-failures
```

## üìà Available Analyses

### Pre-built Analyses

| Analysis | File | Description |
|----------|---------|-------------|
| **Top Products** | `analyses/top_products.sql` | Best-selling products by quantity and revenue |
| **Employee Performance** | `analyses/employee_performance.sql` | Employee performance by sales |
| **Sales Summary** | `analyses/sales_summary.sql` | Monthly sales summary by store |

### Running Analyses

```bash
# Compile analyses
dbt compile --select analyses

# View compiled results in target/compiled/dbt_demo/analyses/
```

*Built with ‚ù§Ô∏è using dbt and Databricks*
>>>>>>> f77c376 (Update README)
